{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from yahooquery import Ticker\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import math\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_n_pages_given_a_soup(soup):\n",
    "    num_of_results_raw_html = soup.find('span', class_='Mstart(15px) Fw(500) Fz(s)').get_text()\n",
    "    num_of_results_split = num_of_results_raw_html.split(' ')\n",
    "    n_results = int(num_of_results_split[-2])\n",
    "    n_pages = math.ceil(n_results/100)\n",
    "    return n_pages\n",
    "\n",
    "def get_symbols_given_a_soup(soup):\n",
    "    symbols = []\n",
    "    symbols_a_html = soup.find_all('a', class_='Fw(600) C($linkColor)')\n",
    "    for symbol in symbols_a_html:\n",
    "        symbols.append(symbol.get_text())\n",
    "    return symbols"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#https://stackoverflow.com/questions/45448994/wait-page-to-load-before-getting-data-with-requests-get-in-python-3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import sys  \n",
    "\n",
    "user_agent = 'Mozilla/5.0 (X11; Linux x86_64 AppleWebKit/537.36 (KHTML, like GECKO) Chrome/33.0.1750.517 Safari/537.36'\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('user-agent={0}'.format(user_agent))\n",
    "\n",
    "browser = webdriver.Chrome(options=options, executable_path='/Users/andrew/Documents/workspace/earnings-surprise-modelling/notebooks/chromedriver/chromedriver')\n",
    "date = '2023-06-12'\n",
    "url = f\"https://finance.yahoo.com/calendar/earnings?day={date}\"\n",
    "browser.get(url)\n",
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "symbols = []\n",
    "n_pages = get_n_pages_given_a_soup(soup)\n",
    "symbols.extend(get_symbols_given_a_soup(soup))\n",
    "\n",
    "if n_pages > 1:\n",
    "    for i in range(1,n_pages):\n",
    "        i_100 = i*100\n",
    "        next_page_url = f'https://finance.yahoo.com/calendar/earnings?day={date}&offset=i_100&size=i_100'\n",
    "        browser.get(url)\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "        symbols.extend(get_symbols_given_a_soup(soup))\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "symbols = list(set(symbols))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(symbols)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}