{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-31 18:14:11--  https://github.com/mozilla/geckodriver/releases/download/v0.33.0/geckodriver-v0.33.0-linux-aarch64.tar.gz\n",
      "^C\n",
      "\n",
      "gzip: stdin: not in gzip format\n",
      "tar: Child returned status 1\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/mozilla/geckodriver/releases/download/v0.33.0/geckodriver-v0.33.0-linux-aarch64.tar.gz\n",
    "!tar -xvzf geckodriver*\n",
    "!chmod +x geckodriver\n",
    "!export PATH=$PATH:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from yahooquery import Ticker\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import math\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/45448994/wait-page-to-load-before-getting-data-with-requests-get-in-python-3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "import sys  \n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('--headless')\n",
    "s = Service('./geckodriver')\n",
    "#user_agent = 'Mozilla/5.0 (X11; Linux x86_64 AppleWebKit/537.36 (KHTML, like GECKO) Chrome/33.0.1750.517 Safari/537.36'\n",
    "#options.add_argument('user-agent={0}'.format(user_agent))\n",
    "# executable_path param is not needed if you updated PATH\n",
    "#driver = webdriver.Chrome(executable_path='/Users/andrew/Documents/workspace/instabot/chromedriver/chromedriver')\n",
    "browser = webdriver.Firefox(options=options, service=s)\n",
    "ticker = 'MSFT'\n",
    "url = f\"https://www.nasdaq.com/market-activity/stocks/{ticker}/earnings\"\n",
    "browser.get(url)\n",
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['04/25/2023', '01/24/2023', '10/25/2022', '07/26/2022']\n"
     ]
    }
   ],
   "source": [
    "all_earnings_tags = soup.find_all('td', class_='earnings-surprise__table-cell')\n",
    "earnings_dates = []\n",
    "for tag in all_earnings_tags:\n",
    "    content = tag.get_text()\n",
    "    if '/' in content:\n",
    "        earnings_dates.append(content)\n",
    "print(earnings_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('--headless')\n",
    "\n",
    "#user_agent = 'Mozilla/5.0 (X11; Linux x86_64 AppleWebKit/537.36 (KHTML, like GECKO) Chrome/33.0.1750.517 Safari/537.36'\n",
    "#options.add_argument('user-agent={0}'.format(user_agent))\n",
    "# executable_path param is not needed if you updated PATH\n",
    "#driver = webdriver.Chrome(executable_path='/Users/andrew/Documents/workspace/instabot/chromedriver/chromedriver')\n",
    "\n",
    "browser = webdriver.Firefox(options=options, executable_path='./geckodriver')\n",
    "ticker = 'ALSN'\n",
    "url = f\"https://marketchameleon.com/Overview/{ticker}/Earnings/Earnings-Dates/\"\n",
    "browser.get(url)\n",
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html_ = str(soup)\n",
    "key_ = html_.find(\"earnings on\")\n",
    "aoi = html_[key_:key_+100]\n",
    "date = \" \".join(aoi.split(\" \")[2:5])\n",
    "is_before = \"BMC\" in aoi\n",
    "is_after = \"AMC\" in aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04979163084373924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earn_date = datetime.strptime(date, '%B %d, %Y')\n",
    "\n",
    "tickers = Ticker(ticker, asynchronous=True)\n",
    "\n",
    "# Default period = ytd, interval = 1d\n",
    "\n",
    "events = tickers.calendar_events\n",
    "\n",
    "earnings_hist = tickers.earnings_trend\n",
    "\n",
    "# if the call is in the morning, previous day close - earnings day open\n",
    "# if the call is in the afternoon, earnings day close - next day open\n",
    "if is_before:\n",
    "    after_date = deepcopy(earn_date) + dt.timedelta(days = 1)\n",
    "    before_date = deepcopy(earn_date) - dt.timedelta(days = 1)\n",
    "elif is_after:\n",
    "    after_date = deepcopy(earn_date) + dt.timedelta(days = 2)\n",
    "    before_date = deepcopy(earn_date)\n",
    "else:\n",
    "    raise KeyError\n",
    "\n",
    "if before_date.weekday() in [5,6]:\n",
    "    before_date = before_date - dt.timedelta(days=before_date.weekday()-4)\n",
    "\n",
    "if after_date.weekday() in [5,6]:\n",
    "    after_date = after_date + dt.timedelta(days = 7-after_date.weekday())\n",
    "\n",
    "# check for federal holidays\n",
    "USFederalHolidayCalendar\n",
    "\n",
    "df = tickers.history(start=before_date, end=after_date, period='1d')\n",
    "\n",
    "(df.iloc[1][\"open\"] - df.iloc[0][\"close\"]) / df.iloc[0][\"close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_date.weekday()\n",
    "after_date in USFederalHolidayCalendar().holidays(start='2014-01-01', end='2030-12-31').to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023-04-27 00:00:00', 3, '2023-05-01 00:00:00', 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(before_date), before_date.weekday(), str(after_date), after_date.weekday() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping over bunches of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UNH', 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = 'UNH'\n",
    "\n",
    "def get_surprise_binary(ticker):\n",
    "    temp = None  # Ensure this variable is cleared\n",
    "    temp = Ticker(ticker)\n",
    "    temp_df = None  # Ensure this variable is cleared\n",
    "    temp_df = temp.earning_history.reset_index().copy()\n",
    "    if temp_df.shape[0] == 0:\n",
    "        return 0\n",
    "    try:\n",
    "        temp_df[\"date\"] = pd.to_datetime(temp_df[\"quarter\"], format=\"%Y-%m-%d\")\n",
    "    except:\n",
    "        print(ticker, temp_df[\"quarter\"])\n",
    "        return 0\n",
    "    # Create new features\n",
    "    temp_df[\"surpriseBinary\"] = temp_df[\"epsDifference\"].apply(\n",
    "        lambda x: 1 if float(x) > 0 else 0\n",
    "    )\n",
    "    \n",
    "    temp_df.sort_values(by=['quarter'],inplace=True,ascending=False)\n",
    "    return ticker, temp_df.surpriseBinary.iloc[0]\n",
    "\n",
    "get_surprise_binary(\"UNH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_mov(ticker):\n",
    "    print(ticker)\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('--headless')\n",
    "    s = Service('./geckodriver')\n",
    "\n",
    "    browser = webdriver.Firefox(options=options, service=s)\n",
    "    url = f\"https://marketchameleon.com/Overview/{ticker}/Earnings/Earnings-Dates/\"\n",
    "    browser.get(url)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    browser.quit()\n",
    "    \n",
    "    html_ = str(soup)\n",
    "    key_ = html_.find(\"earnings on\")\n",
    "    aoi = html_[key_:key_+100]\n",
    "    date = \" \".join(aoi.split(\" \")[2:5])\n",
    "    print(date, aoi)\n",
    "    is_before = \"BMO\" in aoi\n",
    "    is_after = \"AMC\" in aoi\n",
    "    \n",
    "    earn_date = datetime.strptime(date, '%B %d, %Y')\n",
    "\n",
    "    tickers = Ticker(ticker, asynchronous=True)\n",
    "    \n",
    "    # Default period = ytd, interval = 1d\n",
    "    \n",
    "    events = tickers.calendar_events\n",
    "    \n",
    "    earnings_hist = tickers.earnings_trend\n",
    "    \n",
    "    # if the call is in the morning, previous day close - earnings day open\n",
    "    # if the call is in the afternoon, earnings day close - next day open\n",
    "    if is_before:\n",
    "        after_date = deepcopy(earn_date) + dt.timedelta(days = 1)\n",
    "        before_date = deepcopy(earn_date) - dt.timedelta(days = 1)\n",
    "    else:# is_after:\n",
    "        after_date = deepcopy(earn_date) + dt.timedelta(days = 2)\n",
    "        before_date = deepcopy(earn_date)\n",
    "    # else:\n",
    "    #    raise KeyError\n",
    "    \n",
    "    if before_date.weekday() in [5,6]:\n",
    "        before_date = before_date - dt.timedelta(days=before_date.weekday()-4)\n",
    "    \n",
    "    if after_date.weekday() in [5,6]:\n",
    "        after_date = after_date + dt.timedelta(days = 7-after_date.weekday())\n",
    "    \n",
    "    # check for federal holidays\n",
    "    # USFederalHolidayCalendar # TODO\n",
    "    try:\n",
    "        df = tickers.history(start=before_date, end=after_date, period='1d')\n",
    "        return ticker, (df.iloc[1][\"open\"] - df.iloc[0][\"close\"]) / df.iloc[0][\"close\"]\n",
    "    except:\n",
    "        return ticker, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LiveError",
     "evalue": "Only one live display may be active at once",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/joblib/parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLiveError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mesurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      4\u001b[0m tickers \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnp500\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfetch_symbols()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 5\u001b[0m surprise_binary \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_surprise_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m price_mov \u001b[38;5;241m=\u001b[39m parallel_loop(get_price_mov, tickers, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/mlresearch/utils/_parallelize.py:48\u001b[0m, in \u001b[0;36mparallel_loop\u001b[0;34m(function, iterable, n_jobs, progress_bar, description)\u001b[0m\n\u001b[1;32m     46\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m _get_n_jobs(n_jobs)\n\u001b[1;32m     47\u001b[0m iterable \u001b[38;5;241m=\u001b[39m track(iterable, description\u001b[38;5;241m=\u001b[39mdescription) \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;28;01melse\u001b[39;00m iterable\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/joblib/parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    870\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[1;32m    871\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[0;32m--> 873\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mislice(iterator, big_batch_size))\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/mlresearch/utils/_parallelize.py:48\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m _get_n_jobs(n_jobs)\n\u001b[1;32m     47\u001b[0m iterable \u001b[38;5;241m=\u001b[39m track(iterable, description\u001b[38;5;241m=\u001b[39mdescription) \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;28;01melse\u001b[39;00m iterable\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(function)(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m iterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/rich/progress.py:167\u001b[0m, in \u001b[0;36mtrack\u001b[0;34m(sequence, description, total, auto_refresh, console, transient, get_time, refresh_per_second, style, complete_style, finished_style, pulse_style, update_period, disable, show_speed)\u001b[0m\n\u001b[1;32m    145\u001b[0m columns\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m    146\u001b[0m     (\n\u001b[1;32m    147\u001b[0m         BarColumn(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    157\u001b[0m progress \u001b[38;5;241m=\u001b[39m Progress(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39mcolumns,\n\u001b[1;32m    159\u001b[0m     auto_refresh\u001b[38;5;241m=\u001b[39mauto_refresh,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[1;32m    165\u001b[0m )\n\u001b[0;32m--> 167\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_period\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/rich/progress.py:1169\u001b[0m, in \u001b[0;36mProgress.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgress\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/rich/progress.py:1160\u001b[0m, in \u001b[0;36mProgress.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the progress display.\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/rich/live.py:113\u001b[0m, in \u001b[0;36mLive.start\u001b[0;34m(self, refresh)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_live\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_screen:\n",
      "File \u001b[0;32m~/miniconda3/envs/rf84/lib/python3.11/site-packages/rich/console.py:835\u001b[0m, in \u001b[0;36mConsole.set_live\u001b[0;34m(self, live)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 835\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mLiveError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one live display may be active at once\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live \u001b[38;5;241m=\u001b[39m live\n",
      "\u001b[0;31mLiveError\u001b[0m: Only one live display may be active at once"
     ]
    }
   ],
   "source": [
    "from mlresearch.utils import parallel_loop\n",
    "from esurprise.data import DataLoader\n",
    "\n",
    "tickers = DataLoader(\"snp500\").fetch_symbols()[\"symbol\"].tolist()\n",
    "surprise_binary = parallel_loop(get_surprise_binary, tickers, n_jobs=-1, progress_bar=True)\n",
    "price_mov = parallel_loop(get_price_mov, tickers, n_jobs=-1, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'price_mov' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mprice_mov\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_mov\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m res2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m surprise_binary \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(i)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mint\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurp_bin\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m res_total \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([res, res2], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'price_mov' is not defined"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame(price_mov, columns=[\"ticker\", \"price_mov\"]).set_index(\"ticker\")\n",
    "res2 = pd.DataFrame([i for i in surprise_binary if type(i)!=int], columns=[\"ticker\", \"surp_bin\"]).set_index(\"ticker\")\n",
    "res_total = pd.concat([res, res2], axis=1).dropna()\n",
    "res_total[res_total[\"surp_bin\"]>0].median()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
